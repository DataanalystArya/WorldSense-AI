WorldSense-AI  
### Real-Time Image & Video Object Detection System (YOLOv8)

This project started as my attempt to understand how object detection works in real-world systems.
Instead of writing a single script, I structured it like an industry project where image and video
inference, models, and utilities are clearly separated.

### Features Implemented

- Image Object Detection  
- Video Object Detection  
- Multi-object detection  
- Batch video processing  
- CLI-based execution  
- Output saving (images & videos)  

### Tech Stack

- Python  
- YOLOv8 (Ultralytics)  
- OpenCV  
- PyTorch  


### ğŸ“ Project Structure



WorldSense-AI/
â”‚
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ detect_image.py        # Image inference pipeline
â”‚   â”œâ”€â”€ detect_video.py        # Video inference (single & batch processing)
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ yolo/                  # YOLOv8 model loader & configs
â”‚   â”œâ”€â”€ clip/                  # (Planned) Multimodal embeddings
â”‚   â”œâ”€â”€ vit/                   # (Planned) Vision Transformer models
â”‚   â””â”€â”€ ssd/                   # (Planned) SSD-based detection
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ samples/
â”‚   â”‚   â”œâ”€â”€ images/            # Sample input images
â”‚   â”‚   â””â”€â”€ videos/            # Sample input videos
â”‚   â””â”€â”€ labels/                # (Future) Training annotations
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ images/                # Detected image outputs
â”‚   â””â”€â”€ videos/                # Detected video outputs
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ visualization.py       # Bounding box & overlay utilities
â”‚
â”œâ”€â”€ assets/                    # README visuals (screenshots, GIFs)
â”œâ”€â”€ dashboard/                 # (Future) Analytics / UI dashboard
â”œâ”€â”€ trackers/                  # (Future) Object tracking modules
â”œâ”€â”€ training/                  # (Future) Model training pipelines
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ main.py
â””â”€â”€ README.md


## â–¶ï¸ How to Run

### 1. Create virtual environment & install dependencies:-
```bash
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
### 2. How to Run Inference:-

Image Detection
Put your input images inside:
data/samples/images/

Run the image detection pipeline:
python -m inference.detect_image

Detected images will be automatically saved to:
output/images/

### 3. Video Detection (Single Video):-

Place the video file inside:
data/samples/videos/

Run detection on a specific video:
python -m inference.detect_video market.mp4

The detected video will be saved to:
output/videos/

### Video Detection (Batch Mode):-

To run detection on all videos present in the folder:
python -m inference.detect_video

### Image Detection Results
Sample Outputs
![Image Detection 1](assets/demo_image1.jpg)
![Image Detection 2](assets/demo_image2.jpg)
![Image Detection 3](assets/demo_image3.jpg)


### ğŸ¥ Video Detection Demo
### Market Scene Detection
GIF generated from object detection on a crowded market video:

![Market Video Detection](assets/demo_video.gif)

### Highway Scene Detection
GIF generated from object detection on a highway traffic video:

![Highway Video Detection](assets/highway_demo.gif)


### Future Work
-Live camera detection
-Object tracking (DeepSORT / ByteTrack)
-Scene understanding
-CLIP-based zero-shot detection
-Web dashboard & analytics
-Model training pipelines

### Author
Built with â¤ï¸ by Arya Verma
# minor update
